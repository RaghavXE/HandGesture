# âœ‹ HandGesture â€” Real-time Sign Language Translator  

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)  
![PyTorch](https://img.shields.io/badge/PyTorch-ML-orange?logo=pytorch)  
![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-green?logo=opencv)  
![License](https://img.shields.io/badge/License-Educational-lightgrey)  

---



## ğŸ“– Overview  
HandGesture is a **real-time American Sign Language (ASL) translator** built using **Computer Vision (OpenCV + Mediapipe)** and a **Deep Learning model (PyTorch)**.  
It allows users to **translate ASL gestures into text instantly**, bridging the gap between the deaf community and non-signers.  

The project also includes a **simple web interface** for demonstrations, making it accessible and easy to use.  

---



## âœ¨ Features  
- **Real-time detection** of ASL hand gestures using a webcam  
- **Pre-trained MLP model** (`asl_mlp_model.pth`) for gesture classification  
- **Web-based interface** (`index.html`, `run.html`) for interactive usage  
- **Text-to-speech support** for vocalizing translated signs  
- Includes **dataset folder (`asl_alphabet_train/`)** for retraining  

---



## ğŸ›  Tech Stack  
- **Programming Language**: Python 3.10+  
- **Libraries & Frameworks**:  
  - [PyTorch](https://pytorch.org/) â€” Deep Learning  
  - [OpenCV](https://opencv.org/) â€” Computer Vision  
  - [Mediapipe](https://developers.google.com/mediapipe) â€” Hand Landmark Detection  
  - [NumPy](https://numpy.org/) â€” Matrix Computations  
- **Frontend**: HTML, CSS, JavaScript  

---



## âš™ï¸ Installation  

1. **Clone the repository**  
   ```bash
   git clone https://github.com/RaghavXE/HandGesture.git
   cd HandGesture

2. **Install dependencies**
   ```bash
   pip install torch opencv-python mediapipe numpy


3. **Ensure you have a webcam connected.**

  â–¶ï¸ Usage
  ğŸ”¹ Run Real-time Translator
      
      python realtime_asl_translator2.py
      
  ğŸ”¹ Launch Web Interface
      Simply open the files in your browser:
        â€¢ index.html â†’ Main interface
        â€¢ run.html â†’ Gesture translation demo
  
  ğŸ”¹ (Optional) Train Model from Scratch
      
      python New.py
      Dataset used: asl_alphabet_train/
  

## ğŸ“‚ Project Structure

      HandGesture/
      â”‚â”€â”€ New.py                     # Training script
      â”‚â”€â”€ realtime_asl_translator2.py # Real-time ASL translator
      â”‚â”€â”€ asl_mlp_model.pth           # Pre-trained PyTorch model
      â”‚â”€â”€ asl_alphabet_train/         # Training dataset
      â”‚â”€â”€ index.html                  # Web UI (main)
      â”‚â”€â”€ run.html                    # Gesture demo page
      â”‚â”€â”€ script.js                   # Frontend logic
      â”‚â”€â”€ style.css                   # Frontend styling
      â”‚â”€â”€ logo.png                    # Project logo
      â”‚â”€â”€ ankit.jpg                   # Team member photo
      â”‚â”€â”€ anmol.jpg                   # Team member photo
      â”‚â”€â”€ raghav.jpg                  # Team member photo
      â”‚â”€â”€ srisai.jpg                  # Team member photo
      â”‚â”€â”€ README.md                   # Documentation

---
## ğŸ“¸ Demo

  ğŸ¥ Real-time Translation Example:
    
  
---

## ğŸ‘¥ Contributors
    
  ğŸ”¹Raghav â€” Backend Developer 
  
  ğŸ”¹Ankit â€” Model Training & Testing
  
  ğŸ”¹Anmol â€” Dataset Development
  
  ğŸ”¹Sri Sai â€” Frontend Developer
  
  ğŸ”¹Nishant â€” UI/UX & Integration
  

## ğŸ“œ License

  
  This project is released for educational purposes.
  Feel free to fork, modify, and learn from it with proper attribution.
